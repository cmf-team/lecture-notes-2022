\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage[english,russian]{babel}
\usepackage{amsmath}

\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage{tikz}

\usepackage{tcolorbox}


\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{fixltx2e}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\usepackage{geometry}
\geometry{left=25mm,right=25mm,
 top=25mm,bottom=25mm}
 
 \title{Анализ данных.\\
Лекция. Неделя 1-2. \\
Машинное обучение. Классификация: кредитный скоринг.}
\author{Михайлов Даниил}

% Колонтитулы
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0.1mm}  
\renewcommand{\footrulewidth}{0.1mm}
\lfoot{}
\rfoot{\thepage}
\cfoot{}
\rhead{CMF-2022}
\chead{}

\begin{document}
\maketitle

% Оглавление
\setcounter{tocdepth}{2} % {2} - в оглавлении участвуют chapter, section и subsection. {1} - только chapter и section
\renewcommand\contentsname{Содержание}
\tableofcontents
\newpage

% \section{Dictionary, Definitions, Abbreviations}

% \subsection{Dictionary}
% \begin{itemize}
%     \item IR - Interest rate - процентная ставка.
%     \item Compounding - платежи (idk)
% \end{itemize}

% \subsection{Definitions and Abbreviations}
% \begin{itemize}
%     \item SAR - Stated annual rate.
%     \item EAR - Effective annual rate.
%     \item FoC - Frequency of Compounding
%     \item PMT - Payment
%     \item r - Interest rate (at the moment). 
% \end{itemize}

\renewcommand{\labelitemi}{\tiny$\bullet$}
\renewcommand{\figurename}{Fig.}

 \section{Предобработка данных}
 
 \subsection{Изучение исходных данных}
 \begin{itemize}
     \item Размер train и test выборки.
     \item Проверка однородности train и test выборки - дисперсия и мат.ожидание.
     \item Исследуемая переменная: какой тип данных, какие значения принимает, какое распределение?
 \end{itemize}
 
\subsection{Подготовка данных}
 \begin{itemize}
     \item Работа с пропущенными значениями. Их подсчет и замена на среднее, моду. Также можно заменять на нетипичное для остальной выборки значение (например, -99999) - в случае если пропуск в данных является дополнительной информацией. В таком случае возможно добавление новой переменной - есть ли пропуск в данных или нет.
     \item Из данных можно извлечь дополнительные признаки: длина строки, частота встречи в выборке, и т.д.
     \item Из переменных с форматом даты можно извлечь следующие признаки: время года, год, месяц, день, утро/вечер, является ли день выходным или праздником, и т.д.
     
     \item Перевод категориальных признаков в признаки, принимающие значения 0 и 1 - one hot кодирование.
    \begin{center}
     \begin{tabular}{|r|}
     \hline
     gender \\
     \hline\hline
     female \\
     male \\
     female \\
     \hline
     \end{tabular}
     \quad
     \longrightarrow
      \begin{tabular}{|r|l|}
     \hline
     male & female \\
     \hline\hline
     0 & 1 \\
     1 & 0 \\
     0 & 1 \\
     \hline
     \end{tabular}
    \end{center}
     
     \item Стандартизация данных. Приведение к нулевому мат.ожиданию и единичной дисперсии. Таким образом, делаем разницу двух значений у разных параметров сравнимой. (Метрические алгоритмы чувствительны к нормировке, в отличие от алгоритмов, построенных на деревьях).
     \item Добавление признаков, которые являются перемножением уже существующих - для поиска квадратичной зависимости (Но надо помнить о "проклятии размерности").
     
     \item Оптимизация хранения данных. Перевод бинарных признаков в int8.
     
     \item Сохранение данных с их форматами.
     
 \end{itemize}
 
 \newpage
 
 
 \section{Построение алгоритмов}
 \begin{itemize}
  \item Деление выборки на обучающую и тестовую (train-test split). На первой мы будем строить и тренировать модель, на второй - валидировать.
 \end{itemize}
 
  \subsection{Метрики для бинарной классификации}
  \begin{itemize}
   \item \textbf{log\_loss}.\\
   Пусть $y_{true}$ - реальное значение (0 или 1), а $y_{pred}$ - предсказанная нами вероятность принятия значения 1. \\
   Тогда \[log\_loss = y_{true}*log(y_{pred}) + (1 - y_{true})*log(1 - y_{pred})\]
   log\_loss для всей выборки рассчитывается, как среднее log\_loss по каждому измерению.\\
   Чем ниже log\_loss у модели, тем она точнее.\\
   Для многоклассовой классификации можно использовать multi class log loss.
   
   \item Confusion Matrix. \\
   Перед построением матрицы и использованием дальнейших метрик необходимо подобрать порог, начиная с которого мы будем предсказывать 1. Например, 0.5. Тогда набор полученных моделью значений вероятностей (0.64, 0.38, 0.86, 0.12) превратиться в предсказания (1, 0, 1, 0).
   \begin{center}
   \begin{tabular}{|r||r|r|}
     \hline
      Предсказания \rightarrow \\Реальность \downarrow&0&1 \\
     \hline\hline
     0&True Negative&False Positive \\
     \hline
     1&False Negative&True Positive \\
     \hline
     \end{tabular}
    \end{center}
    
    \item \textbf{Accuracy}. \[(TN + TP)/(TN + TP + FN + FP)\] 
    То есть отношение верно сделанных предсказаний ко всем.
    
    \item \textbf{Precision}. \[TP/(TP + FP)\] Какая доля единиц, которые мы предсказали, верна.
    
    \item \textbf{Recall}. \[TP/(TP + FN)\] Какую часть настоящих единиц мы покрыли нашими предсказаниями?
    
    \item \textbf{f1 score}. \[(2*Precision*Recall)/(Precision+Recall)\] Баланс между Precision и Recall.
    
    \item \textbf{ROC curve}.\\
    Процесс построения: \\
    
    1) Сортируем значения по предсказанной нами вероятности\\
    
    2) Получаем вектор реальных значений в определенном порядке \\
    
    \begin{tabular}{|r|l|}
     \hline
     Модель & True \\
     \hline\hline
     0.4 & 1 \\
     0.2 & 0 \\
     0.1 & 0 \\
     0.5 & 1 \\
     0.6 & 0 \\
     0.7 & 1 \\
     \hline
    \end{tabular}
    \quad
    \longrightarrow
    \quad
    \begin{tabular}{|r|l|}
     \hline
     Модель & True \\
     \hline\hline
     0.1 & 0 \\
     0.2 & 0 \\
     0.4 & 1 \\
     0.5 & 1 \\
     0.6 & 0 \\
     0.7 & 1 \\
     \hline
    \end{tabular}
    \quad
    \longrightarrow
    \quad
    \begin{pmatrix}
    0&0&1&1&0&1
    \end{pmatrix}\\
    
    3) Идем по порядку значений в этом векторе. Ноль означает сдвиг вверх на один шаг, единица - сдвиг вправо на один шаг.\\
    
    4) Получаем ступенчатую фигуру. ROC AUC score - площадь под этой кривой.\\
    
    Идеальный случай, когда у нас сначала все нули, потом все единицы - тогда площадь равна единице. В обратном случае она равну нулю.\\
    Случайным предсказаниям соответствует ROC AUC равный примерно 0.5.
    
    \item \textbf{top k Precision}.\\
    Мы сортируем предсказания по вероятности (так же, как для ROC), и берем только k предсказаний с самой высокой вероятностью, на которых будем использовать Precision.
    
  \end{itemize}
  
  \textbf{Пример задач с лекции:}
  \begin{itemize}
  \item Для зенитчика нужно определить, дружеский (0) или вражеский (1) самолет в небе, какую метрику оптимизировать?\\
  
  Ответ: Precision, так как подбить дружеский самолет хуже, чем не подбить вражеский.\\
  
  \item Нужно построить алгоритм, который будет искать мошеннические (1) транзакции среди обычных (0) для отправки их на дополнительную проверку. Какую метрику оптимизировать?\\
  
  Ответ: Recall (полнота), так как важно найти все плохие транзакции; то, что будут лишний раз проверены некоторые обычные не так важно.\\
  
  \item Мы хотим отправить смс сообщения тем 1000 клиентам из нашей базы в 10000000 людей, которые с наибольшим шансом откликнуться на них - какую метрику оптимизировать?\\
  
  Ответ: Roc\_auc - тогда отправим топ 1000 после сортировки по вероятностям. Аналогично можно поступить с top\_k\_precision.
  \end{itemize}

 \subsection{Бинарная классификация}
 \subsubsection{Предсказание константой}
 \begin{itemize}
  \item В качестве предсказаний мы можем всегда давать одно и то же число: например, 0.5 при бинарной классификации (0 или 1).
  \item Поиск лучшей константы зависит от метрики качества и баланса классов в выборке.
  \item Константа хорошо подходит в качестве базового решения, с которым будут сравниваться последующие решения.
 \end{itemize}
 
 \subsubsection{Модели}
  \begin{itemize}
 \item Для осуществления бинарной классификации можно использовать модели Логистической регрессии, Решающего дерева или kNN (Ближайшие соседи).
 
 \item Последний, в отличие от остальных является метрическим, а не параметрическим алгоритмом. Это значит, что у него нет параметров и он ничего не обучает (как, например, логистическая регрессия в процессе обучения находит параметры - коэффициенты) - kNN имеет только гиперпараметры - то есть те, которые задаются нами, а не определяются моделью при оптимизации.
 
 \item Помимо этого, для kNN очень важно, чтобы исходные данные были приведены к нормальному виду (нулевое мат.ожидание и единичная дисперсия).
 
 \end{itemize}
 
 
 \subsection{Кросс-валидация}
  \begin{itemize}
    \item Разбиваем выборку на сколько-то частей [X1, X2, X3, X4]; обучаемся на [X1, X2, X3] и смотрим качество на [X4], - повторяем для всех возможных комбинаций и определяем среднюю точность.
    
    \item Используя кросс-валидацию, можно подбирать гиперпараметры модели - то есть те, которые задаются нами, а не определяются моделью при оптимизации.
    
    \item Просто перебрав какое-то количество возможных гиперпараметров в кроссвалидации, выберем тот, при котором точность максимальна.
    \end{itemize}
    

\section{Blending}
\begin{itemize}
\item усреднение результатов нескольких моделей может привести к улучшению их точности.
\item Пусть имеем две модели с предсказаниями $y_{pred\_1}$ и $y_{pred\_2}$.\\
Тогда
\[y_{pred} = \alpha * y_{pred\_1} + (1-\alpha)*y_{pred\_2} \]
Оптимальный параметр альфа можно найти с помощью кросс-валидации.  
\end{itemize}


\section{Pipeline}
\begin{itemize}
\item Pipeline - это алгоритм, последовательность действий, которая полностью преобразует исходные данные в предсказания.

\item В pipeline мы сразу же подставляем подобранные гиперпараметры, с которыми модели работали точнее всего.
\end{itemize}
 
\end{document}
